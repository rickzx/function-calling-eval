{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 37.23ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 48.29ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 45.98ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/riczhou/hermes-function-calling-v1-split/commit/1540c59cfd30988079f374785ce44b776b00cff0', commit_message='Upload dataset', commit_description='', oid='1540c59cfd30988079f374785ce44b776b00cff0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/riczhou/hermes-function-calling-v1-split', endpoint='https://huggingface.co', repo_type='dataset', repo_id='riczhou/hermes-function-calling-v1-split'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fc = load_dataset(\"NousResearch/hermes-function-calling-v1\", \"func_calling_singleturn\", split=\"train\")\n",
    "\n",
    "# Split into train, validation, test 8:1:1\n",
    "train = fc.train_test_split(test_size=0.2, seed=42)['train']\n",
    "val_test = fc.train_test_split(test_size=0.5, seed=42)['test']\n",
    "val = val_test.train_test_split(test_size=0.5, seed=42)['train']\n",
    "test = val_test.train_test_split(test_size=0.5, seed=42)['test']\n",
    "\n",
    "train.push_to_hub(\"riczhou/hermes-function-calling-v1-split\", split=\"train\")\n",
    "val.push_to_hub(\"riczhou/hermes-function-calling-v1-split\", split=\"validation\")\n",
    "test.push_to_hub(\"riczhou/hermes-function-calling-v1-split\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Trigger Notifications with a POST Request', 'conversations': [{'from': 'system', 'value': \"You are a function calling AI model. You are provided with function signatures within <tools> </tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.\\n<tools>\\n[{'type': 'function', 'function': {'name': 'configureJiraNotificationWorkflow', 'description': 'Sets up an automated workflow to send notifications via POST request when specified events occur in Jira.', 'parameters': {'type': 'object', 'properties': {'issue_tracking_system': {'type': 'string', 'description': 'The issue tracking system to monitor for events.'}, 'notification_endpoint': {'type': 'string', 'description': 'The endpoint URL to send the POST request for notifications.'}, 'event_types': {'type': 'array', 'description': 'List of event types to trigger notifications.', 'items': {'type': 'string'}}}, 'required': ['issue_tracking_system', 'notification_endpoint', 'event_types']}}}]\\n</tools>\\nFor each function call return a json object with function name and arguments within <tool_call> </tool_call> tags with the following schema:\\n<tool_call>\\n{'arguments': <args-dict>, 'name': <function-name>}\\n</tool_call>\\n\"}, {'from': 'human', 'value': \"I am overseeing a project and need to implement an automated notification system using our Jira issue tracking. The requirement is for a webhook to send POST requests to our designated notification service endpoint at 'https://api.notify.example.com' whenever issues are either created or updated in Jira. These notifications must carry essential details such as the issue ID, its summary, and status. Utilizing the function 'configureJiraNotificationWorkflow', I'd like to set up a workflow specific to the Jira events 'issue_created' and 'issue_updated' to interact with our service endpoint.\\n\\nCould you assist in calling the necessary functions to get this automation in place with the specification provided?\"}, {'from': 'gpt', 'value': \"<tool_call>\\n{'arguments': {'issue_tracking_system': 'Jira', 'notification_endpoint': 'https://api.notify.example.com', 'event_types': ['issue_created', 'issue_updated']}, 'name': 'configureJiraNotificationWorkflow'}\\n</tool_call>\\n\"}], 'category': 'API Call', 'subcategory': 'Workflow Automation', 'id': '19004c3d-4502-4a58-aced-385d69c325e9'}\n"
     ]
    }
   ],
   "source": [
    "# Show first test example\n",
    "print(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sample(sample):\n",
    "    assert len(sample[\"conversations\"]) == 3\n",
    "\n",
    "    system = None\n",
    "    human = None\n",
    "    gpt = None\n",
    "\n",
    "    for turns in sample[\"conversations\"]:\n",
    "        if turns[\"from\"] == \"system\":\n",
    "            system = turns[\"value\"]\n",
    "        elif turns[\"from\"] == \"human\":\n",
    "            human = turns[\"value\"]\n",
    "        elif turns[\"from\"] == \"gpt\":\n",
    "            gpt = turns[\"value\"]\n",
    "\n",
    "    return {\n",
    "        \"system\": system,\n",
    "        \"human\": human,\n",
    "        \"gpt\": gpt\n",
    "    }\n",
    "\n",
    "sample = split_sample(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'gather_social_media_data', 'arguments': {'platforms': ['Facebook', 'Twitter', 'Instagram'], 'metrics': ['likes', 'comments', 'shares', 'new followers'], 'time_period': 'weekly'}}, {'name': 'optimize_google_ads_bids', 'arguments': {'campaign_id': '12345', 'optimization_strategy': 'return_on_ad_spend', 'target_roas': 4.0}}, {'name': 'generate_seo_reports', 'arguments': {'domains': ['trendytech.com'], 'report_type': 'link_building', 'frequency': 'monthly'}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'gather_social_media_data',\n",
       "  'arguments': {'platforms': ['Facebook', 'Twitter', 'Instagram'],\n",
       "   'metrics': ['likes', 'comments', 'shares', 'new followers'],\n",
       "   'time_period': 'weekly'}},\n",
       " {'name': 'optimize_google_ads_bids',\n",
       "  'arguments': {'campaign_id': '12345',\n",
       "   'optimization_strategy': 'return_on_ad_spend',\n",
       "   'target_roas': 4.0}},\n",
       " {'name': 'generate_seo_reports',\n",
       "  'arguments': {'domains': ['trendytech.com'],\n",
       "   'report_type': 'link_building',\n",
       "   'frequency': 'monthly'}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "from typing import List, Optional, Dict, Union\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_json_string(s: str) -> str:\n",
    "    s = s.replace('\\\\\\\\n', '').replace('\\\\n', '')\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "\n",
    "def parse_completion(gpt: str) -> Optional[List[Dict[str, Union[str, dict]]]]:\n",
    "    try:\n",
    "        if not isinstance(gpt, str):\n",
    "            raise ValueError(f\"Input must be a string, got {type(gpt)}\")\n",
    "        \n",
    "        if not gpt.strip():\n",
    "            return None\n",
    "            \n",
    "        pattern = r\"<tool_call>(.*?)</tool_call>\"\n",
    "        matches = re.findall(pattern, gpt, re.DOTALL)\n",
    "        \n",
    "        if not matches:\n",
    "            return None\n",
    "            \n",
    "        valid_tools = []\n",
    "        \n",
    "        for potential_json in matches:\n",
    "            try:\n",
    "                cleaned_json = clean_json_string(potential_json)\n",
    "                \n",
    "                if not cleaned_json:\n",
    "                    continue\n",
    "                \n",
    "                # First try to parse as regular JSON\n",
    "                try:\n",
    "                    tool_call_json = json.loads(cleaned_json)\n",
    "                except json.JSONDecodeError:\n",
    "                    # If JSON parsing fails, try converting single quotes to double quotes\n",
    "                    try:\n",
    "                        # Use ast.literal_eval to safely evaluate the string as a Python literal\n",
    "                        tool_call_json = ast.literal_eval(cleaned_json)\n",
    "                    except (SyntaxError, ValueError) as e:\n",
    "                        # If both methods fail, try replacing single quotes with double quotes\n",
    "                        # but only for the outermost quotes\n",
    "                        if cleaned_json.startswith(\"'\") and cleaned_json.endswith(\"'\"):\n",
    "                            cleaned_json = cleaned_json[1:-1]  # Remove outer quotes\n",
    "                            cleaned_json = f'\"{cleaned_json}\"'  # Add double quotes\n",
    "                            try:\n",
    "                                tool_call_json = json.loads(cleaned_json)\n",
    "                            except:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "                \n",
    "                if not isinstance(tool_call_json, dict):\n",
    "                    continue\n",
    "\n",
    "                restructured_tool = restructure_tool_call(tool_call_json)\n",
    "                \n",
    "                if restructured_tool['name'] is not None:\n",
    "                    valid_tools.append(restructured_tool)\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return valid_tools if valid_tools else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def restructure_tool_call(data: Dict) -> Dict:\n",
    "    result = {'name': None, 'arguments': {}}\n",
    "    \n",
    "    def extract_fields(d):\n",
    "        for k, v in d.items():\n",
    "            if k == 'name' and result['name'] is None:\n",
    "                result['name'] = v\n",
    "            elif k == 'arguments' and not result['arguments']:\n",
    "                result['arguments'] = v\n",
    "            elif isinstance(v, dict):\n",
    "                extract_fields(v)\n",
    "    \n",
    "    extract_fields(data)\n",
    "    \n",
    "    if result['name'] is None and 'name' in result['arguments']:\n",
    "        result['name'] = result['arguments'].pop('name')\n",
    "    \n",
    "    if not result['arguments']:\n",
    "        result['arguments'] = {k: v for k, v in data.items() \n",
    "                             if k != 'name' and k != 'arguments'}\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def validate_tool_calls(tool_calls: List[Dict]) -> List[Dict]:\n",
    "    valid_calls = []\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        if not isinstance(tool_call, dict):\n",
    "            continue\n",
    "            \n",
    "        required_fields = {'name', 'arguments'}\n",
    "        if not all(field in tool_call for field in required_fields):\n",
    "            continue\n",
    "            \n",
    "        if not isinstance(tool_call['name'], str):\n",
    "            continue\n",
    "            \n",
    "        if not isinstance(tool_call['arguments'], dict):\n",
    "            continue\n",
    "            \n",
    "        valid_calls.append(tool_call)\n",
    "        \n",
    "    return valid_calls\n",
    "\n",
    "\n",
    "completions = parse_completion(sample[\"gpt\"])\n",
    "print(completions)\n",
    "completions = validate_tool_calls(completions)\n",
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 out of 474 samples have valid completions\n"
     ]
    }
   ],
   "source": [
    "# verify how many samples in the test set have valid completions\n",
    "\n",
    "valid_completions = 0\n",
    "\n",
    "for sample in test:\n",
    "    sample = split_sample(sample)\n",
    "    completions = parse_completion(sample[\"gpt\"])\n",
    "    if completions is None:\n",
    "        continue\n",
    "    completions = validate_tool_calls(completions)\n",
    "    if completions:\n",
    "        valid_completions += 1\n",
    "\n",
    "print(f\"{valid_completions} out of {len(test)} samples have valid completions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "function_calling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
